synchronization layer

content: (opaque at this layer, but transparent to application layer)
  set of key/value pairs, encrypted en mass with a single key (which means they must share the same set of authorized readers)
  hash of key used to encrypt

chunk:
  immutable unique name
  immutable content (fixed size, e.g. 8KB)
  immutable signature of writer

snapshot:
  immutable set of chunks
  immutable set of encrypted keys (one for each applicable key/reader combination) as chunks
  immutable signature of writer

channel:
  immutable unique name
  mutable set of authorized writers (don't need to track authorized readers since only those who can prove they can decrypt a given chunk will be sent it)
  mutable map of writers to snapshots

user:
  public/private keypair


application layer (firebase)

The webapp includes its rules JSON as part of its static content (e.g. in a .js file) and uses it to determine lists of authorized readers and writers for each key/value pair added/updated/deleted in a given incoming or outgoing diff.

For incoming diffs, each change is validated and authenticated according to the rules and the identity of the publisher.  If any rule is violated, or authentication fails, the diff is discarded.

For outgoing diffs, each change is encrypted with a key specific to the set of authorized readers for that node.  If such a key does not yet exist, it is created, encrypted separately for each reader, and included as part of the snapshot.

Note that when a new reader is added to an existing list of readers, it may be possible to continue using the existing key if that key is not also used for content off limits to the new reader.  However, if a reader is removed from the list, a new key must be generated (or a more restricted existing key selected), and it may also be desireable to re-encrypt content which used the obsolete key.

Diffs are serialized as chunks by grouping them by encryption key and dividing each group into a minimum set of chunks required to update the subscriber.  These chunks are sent to the subscriber, followed by a signed manifest of chunks and key IDs representing the snapshot (with new chunks added and obsolete chunks removed).


events

auth request #n result or error

write request #n complete (server acknowledged) or error

transaction request #n result (peer acknowledged, possible error, snapshot of result regardless of success)

need new value for transaction request #n

query #n diff (from local or remote write) or error (e.g. permission)

onDisconnect write patch request #n complete (server acknowledged) or error


consistency

The server chooses a global order for updates, and each update has a prerequisite such that it is only accepted if it immediately follows its prerequisite in the global order.  This makes every update atomic.  Clients trust but verify by checking that updates have arrived in an order consistent with the prerequisite chain.

To post an update, the writer posts a single trie with the hash of the previously published trie as a prequisite.  The server accepts the trie iff the prequisite matches and each ACL-specific subtrie is signed by an authorized writer and is the newest available revision for that ACL, according to the revision number.  A reader accepts all or part of the trie depending on what it considers to be the newest revision for each ACL and sanitizes the result by eliminating values which fail to validate (or picking an alternative if available).

We should disallow forks entirely by insisting that each write must incrementally build on the last, which means un-persisted writes must either be discarded or merged locally if the server reboots.  A merge is only possible if all the data to be merged is writable by the writer, so it may be best to limit expectations and just always discard.

A receiver should never accept an update from the server that's older in any way than the last persisted revision.

Sanitizing a trie incrementally: Use the rules and diff elements to update a dependency DAG.  Then, use the diff elements to create a spanning forest which includes all values directly or indirectly depending on those elements or depended on by those elements.  Next, use the rules to uniquely choose among available alternatives, starting with the least dependent and finishing with the most dependent, breaking ties lexographically.  Finally, collect any changes and apply them to the sanitized trie.

Prohibit cyclical dependencies when parsing rules.json to ensure that the dependency graph is acyclic.

Each chunk should include the hash of the ACL it belongs to so it can't be replayed in a different context.  If an ACL trie later becomes empty, it should remain in the top level trie as a tombstone to prevent replays.  The server should verify both of these things before accepting a new trie, as well as that each ACL trie only contains chunks signed by writers listed in the ACL.


receiving chunks

 * start in a clean, consistent state, containing:
   * "received", the union of sets of chunks for each revision (e.g. persisted and published) being tracked by the server
   * "missing", a DAG of groups and the members they are missing directly or indirectly (initially empty).  An element is not considered missing if it belongs to a data element to which I do not have read access.
   * "incomplete", a set of root chunk names labeled by the server but not yet complete (initially empty)
   * "roots", the current persisted state for each chunk, including:
     * "name", the name of the root chunk
     * "tree", the sync tree of sync trees
     * "acl", the ACL trie listing readers and writers and signed by a key in the admin list (which is either included as part of the app or provided by the user)
     * "rules", a trie-ified, somewhat restricted version of a Firebase rules.json, also signed by the admin
     * "unsanitized", the current data trie, each element being a set of possible values, annotated with 
     * "dependencies", a DAG of elements and the elements they depend on, derived from the current published rules applied to the unsanitized data 
     * "base" is the sanitized version of "unsanitized", which a unique (or no) value selected for each element according to the sanitizing algorithm

 * receive chunks and update "received" and "missing" (sending nacks as necessary) until one of the "incomplete" chunks is complete (i.e. has no missing chunks)
 
 * if the "new" root is older than the current persisted root, bail out and start again from the clean state.  Do the same if any of the following validation steps fail.
 
 * diff the old ACL chunks with the new ACL chunks, resulting in the tuple (obsoleteACLChunks, newACLChunks)
 
 * apply the above diff to the ACL sync tree, resulting in the tuple (obsoleteACLValues, newACLValues)
 
 * apply the above diff to the ACL trie
 
 * diff the old data chunks with the new data chunks, resulting in the tuple (obsoleteDataChunks, newDataChunks)
 
 * apply the above diff to the data sync tree, resulting in the tuple (obsoleteDataValues, newDataValues)

 * repeat the ACL process above for each element of the data diff, verifying that each resulting local ACL is either a strict subset of the top-level ACL or a tombstone

 * if the ACL contains me as a reader, decrypt the key and use it to decrypt the leaves below.  Otherwise, skip that data element and move on to the next one.

 * validate each element of the data diff, ensuring no element is removed without at least a tombstone (i.e. empty leaf trie) to replace it, that there are no duplicates, that each element is signed by a writer listed in the local ACL, and that each new element is newer than the obsolete one

 * for each element of the data diff, do the chunk->tree->trie diff process on the leaf trees, verifying that each leaf is marked with the hash of the ACL of the data element it belongs to, and that it is signed by a writer in that ACL

 * apply each data diff to its respective data trie

 * tag the new root, and if it's the published one notify the application that it has changed

 * clear the "missing" DAG, add any new chunks to the old (clean) "received" set, remove any obsolete ones that aren't still part of another tagged root (which probably means maintining a set of chunks for each root as well as the union of them all), and clear the "incomplete" set

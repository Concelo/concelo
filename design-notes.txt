synchronization layer

content: (opaque at this layer, but transparent to application layer)
  set of key/value pairs, encrypted en mass with a single key (which means they must share the same set of authorized readers)
  hash of key used to encrypt

chunk:
  immutable unique name
  immutable content (fixed size, e.g. 8KB)
  immutable signature of writer

snapshot:
  immutable set of chunks
  immutable set of encrypted keys (one for each applicable key/reader combination) as chunks
  immutable signature of writer

channel:
  immutable unique name
  mutable set of authorized writers (don't need to track authorized readers since only those who can prove they can decrypt a given chunk will be sent it)
  mutable map of writers to snapshots

user:
  public/private keypair


application layer (firebase)

The webapp includes its rules JSON as part of its static content (e.g. in a .js file) and uses it to determine lists of authorized readers and writers for each key/value pair added/updated/deleted in a given incoming or outgoing diff.

For incoming diffs, each change is validated and authenticated according to the rules and the identity of the publisher.  If any rule is violated, or authentication fails, the diff is discarded.

For outgoing diffs, each change is encrypted with a key specific to the set of authorized readers for that node.  If such a key does not yet exist, it is created, encrypted separately for each reader, and included as part of the snapshot.

Note that when a new reader is added to an existing list of readers, it may be possible to continue using the existing key if that key is not also used for content off limits to the new reader.  However, if a reader is removed from the list, a new key must be generated (or a more restricted existing key selected), and it may also be desireable to re-encrypt content which used the obsolete key.

Diffs are serialized as chunks by grouping them by encryption key and dividing each group into a minimum set of chunks required to update the subscriber.  These chunks are sent to the subscriber, followed by a signed manifest of chunks and key IDs representing the snapshot (with new chunks added and obsolete chunks removed).


events

auth request #n result or error

write request #n complete (server acknowledged) or error

transaction request #n result (peer acknowledged, possible error, snapshot of result regardless of success)

need new value for transaction request #n

query #n diff (from local or remote write) or error (e.g. permission)

onDisconnect write patch request #n complete (server acknowledged) or error


consistency

The server chooses a global order for updates, and each update has a prerequisite such that it is only accepted if it immediately follows its prerequisite in the global order.  This makes every update atomic.  Clients trust but verify by checking that updates have arrived in an order consistent with the prerequisite chain.

The server should send all updates it receives (minus those that are obsoleted by the same writer), leaving the clients to apply the rules and weed out bad updates.  If more than one valid update remains that satisifies both the rules and a common space in the prereq chain, the first to arrive according to the order the server sent them will win.

Note the server can't even throw out an update that seems to fail the prerequisite ordering, since a whole sequence in front of it may be invalid according to the rules.  This means the prerequisite field should probably be hidden (encrypted) from the server, since it can't do anything with it.

If the server is sneaky, it can send different orders to different consumers by forking when there's more than one "simultaneous" write, but that just amounts to creating an artificial partition, which is already possible via selective delivery of updates.

A prerequisite consists of a list of update hashes, one for every other writer besides the writer of the given update.

Addendums:

Actually, the server should still throw out misordered updates, since the writer can/should at least acknowledge an invalid write in its revised update.  Syncing and signing the whole top-level tree (including everyone's latest writes) in write order might be the most natural way to do this.

The grouping from the top should be by writer, then ACL, then values, so it's easy/efficient for the server to censor unreadable data for each reader.

Every chunk should be signed by the writer and annotated with the encryption key used for all chunks at or below so they can be forwarded before the entire sync has arrived.

If the server fails and forgets everything, it should grab the most recent snapshot from the persistent store and rely on users to push their updated view of the state as they can.  (Provide API option to indicate when an update is synced to the persistent store.)  This may lead to accidental (or even intentional) forks due to users connecting during the window of time after the server restores from persistence and before anyone can push the latest state, in which case merging is necessary, and the merged tree must reference all of the inputs to the merge so that it can be independently validated.

Each write consists of the writer's latest updates (in the form of a trie) plus the signed tries of any other writers' which are referenced (these are implicitly asserted to be the latest tries the writer has received from those other writers).  Validation involves applying the rules JSON to the new trie, verifying that each write is signed by an appropriate party and that write appears in the latest referenced trie signed by that party (in addition to the new trie).  If the receiver happens to have a newer tries than those referenced (which could be due to a fail/restore scenario as described above, a misbehaving server, or a misbehaving user), it should merge them and publish the result.

Note that users (and misbehaving servers) may have opportunities to fork the database and thereby suppress writes or deletes they don't like, and this may fool users who don't (yet) have access to newer information, but this can be eventually rectified once someone publishes the newer tries.  The server always has the power to partition and/or deny service, but it can't decode that data to make fine-grained decisions unless a user cooperates, and the user can't prevent the server from publishing what it doesn't like unless the server cooperates with it.

Because newly-connected users will not generally have enough information to validate rules which depend on the previous state of the database (we do not keep a complete chain of writes from the beginning, nor do we prohibit combining writes into a single operation), rules must only be written in terms of the current state of the database (i.e. the "root" and "data" fields in Firebase's model are not available, only the "newData" field).

Each signed trie should include a hash of the database URL to prevent replays in different contexts.

Each chunk should include a signature, the key used to encrypt it (or all its children), if applicable, and the revision number when it was introduced.

A write should consist of the latest known writes from everyone (valid or invalid), including the new trie the writer is publishing, the set of tries that trie builds upon (one for a fast-forward, two or more for a merge), and the sets of tries they build upon, etc, ending only at any trie which has been superceded higher in the chain.  The trie(s) the writer has built upon will normally be among the latest writes from others, but may include older writes if the writer considers one or more of the latest writes to be invalid, and may even be empty if the writer has never seen a write from anyone else which it considers valid.

The revision number for a write is one more than the highest revision number among its dependencies.  Note that a revision number does not uniquely identify a revision due to accidental or in; only a hash does that.

A writer may omit another writer's write if the other writer is/was using the same key (e.g. same user logged in on multiple devices or disconnected and later reconnected), but should not do so until that session has clearly been abandoned (e.g. hasn't pinged for ten minutes or more by the local clock).  "Should" being the operative word since no-one else will try to enforce this.  Pings consist of re-publishing the latest trie periodically if no other activity occurs.

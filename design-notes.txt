synchronization layer

content: (opaque at this layer, but transparent to application layer)
  set of key/value pairs, encrypted en mass with a single key (which means they must share the same set of authorized readers)
  hash of key used to encrypt

chunk:
  immutable unique name
  immutable content (fixed size, e.g. 8KB)
  immutable signature of writer

snapshot:
  immutable set of chunks
  immutable set of encrypted keys (one for each applicable key/reader combination) as chunks
  immutable signature of writer

channel:
  immutable unique name
  mutable set of authorized writers (don't need to track authorized readers since only those who can prove they can decrypt a given chunk will be sent it)
  mutable map of writers to snapshots

user:
  public/private keypair


application layer (firebase)

The webapp includes its rules JSON as part of its static content (e.g. in a .js file) and uses it to determine lists of authorized readers and writers for each key/value pair added/updated/deleted in a given incoming or outgoing diff.

For incoming diffs, each change is validated and authenticated according to the rules and the identity of the publisher.  If any rule is violated, or authentication fails, the diff is discarded.

For outgoing diffs, each change is encrypted with a key specific to the set of authorized readers for that node.  If such a key does not yet exist, it is created, encrypted separately for each reader, and included as part of the snapshot.

Note that when a new reader is added to an existing list of readers, it may be possible to continue using the existing key if that key is not also used for content off limits to the new reader.  However, if a reader is removed from the list, a new key must be generated (or a more restricted existing key selected), and it may also be desireable to re-encrypt content which used the obsolete key.

Diffs are serialized as chunks by grouping them by encryption key and dividing each group into a minimum set of chunks required to update the subscriber.  These chunks are sent to the subscriber, followed by a signed manifest of chunks and key IDs representing the snapshot (with new chunks added and obsolete chunks removed).


events

auth request #n result or error

write request #n complete (server acknowledged) or error

transaction request #n result (peer acknowledged, possible error, snapshot of result regardless of success)

need new value for transaction request #n

query #n diff (from local or remote write) or error (e.g. permission)

onDisconnect write patch request #n complete (server acknowledged) or error


consistency

The server chooses a global order for updates, and each update has a prerequisite such that it is only accepted if it immediately follows its prerequisite in the global order.  This makes every update atomic.  Clients trust but verify by checking that updates have arrived in an order consistent with the prerequisite chain.

To post an update, the writer posts a single trie with the hash of the previously published trie as a prequisite.  The server accepts the trie iff the prequisite matches and each ACL-specific subtrie is signed by an authorized writer and is the newest available revision for that ACL, according to the revision number.  A reader accepts all or part of the trie depending on what it considers to be the newest revision for each ACL and sanitizes the result by eliminating values which fail to validate (or picking an alternative if available).

We should disallow forks entirely by insisting that each write must incrementally build on the last, which means un-persisted writes must either be discarded or merged locally if the server reboots.  A merge is only possible if all the data to be merged is writable by the writer, so it may be best to limit expectations and just always discard.

A receiver should never accept an update from the server that's older in any way than the last persisted revision.

Sanitizing a trie incrementally: Use the rules and diff elements to update a dependency DAG.  Then, use the diff elements to create a spanning forest which includes all values directly or indirectly depending on those elements or depended on by those elements.  Next, use the rules to uniquely choose among available alternatives, starting with the least dependent and finishing with the most dependent, breaking ties lexographically.  Finally, collect any changes and apply them to the sanitized trie.

Prohibit cyclical dependencies when parsing rules.json to ensure that the dependency graph is acyclic.

Each chunk should include the hash of the ACL it belongs to so it can't be replayed in a different context.  If an ACL trie later becomes empty, it should remain in the top level trie as a tombstone to prevent replays.  The server should verify both of these things before accepting a new trie.
